{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import numpy.linalg as la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing and setting up data\n",
    "\n",
    "family = pd.read_csv('famb.data', delim_whitespace=True, header=None, index_col=0) # Load data\n",
    "family = family.rename(columns={1: 'Mom_educ', 2: 'Dad_educ', 3: 'Num_siblings', 4: 'Urban', 5:'Nuclear', 6:'Family_income', 7:'South', 8:'AFQT_score'}) # Name columns\n",
    "family = family.replace(-9999, np.nan) # Replacing NaN values\n",
    "column_values = family['Family_income'].values # storing values as a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mom_educ\n",
      "Minimum value: 0\n",
      "Maximum value: 20\n",
      "-----------------\n",
      "Dad_educ\n",
      "Minimum value: 0\n",
      "Maximum value: 20\n",
      "-----------------\n",
      "Num_siblings\n",
      "Minimum value: 0\n",
      "Maximum value: 15\n",
      "-----------------\n",
      "Urban\n",
      "Minimum value: 0\n",
      "Maximum value: 1\n",
      "-----------------\n",
      "Nuclear\n",
      "Minimum value: 0\n",
      "Maximum value: 1\n",
      "-----------------\n",
      "Family_income\n",
      "Minimum value: 0.0\n",
      "Maximum value: 150347.1\n",
      "-----------------\n",
      "South\n",
      "Minimum value: 0\n",
      "Maximum value: 1\n",
      "-----------------\n",
      "AFQT_score\n",
      "Minimum value: 1\n",
      "Maximum value: 99\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "# Print min and max values for each variable.\n",
    "\n",
    "for column in family.columns:\n",
    "    # Find the minimum value of the column\n",
    "    min_value = family[column].min()\n",
    "\n",
    "    # Find the maximum value of the column\n",
    "    max_value = family[column].max()\n",
    "\n",
    "    print(column)\n",
    "    print(\"Minimum value:\", min_value)\n",
    "    print(\"Maximum value:\", max_value)\n",
    "    print('-----------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and setting up education data for the schooling variable.\n",
    "\n",
    "edu = pd.read_csv('ed.data', delim_whitespace=True, header=None, index_col=0) # Loading education data\n",
    "new_column_names = [str(year) for year in range(1979, 1991)] \n",
    "edu.columns = new_column_names # Rename the columns\n",
    "edu = edu.replace(-9999, np.nan) # Define the NaN values\n",
    "edu.index.name = 'id' # creating id column\n",
    "panel_edu = edu.reset_index().melt(id_vars='id', var_name='Year', value_name='Education') # Reformatting data\n",
    "\n",
    "shifted_edu = edu.shift(-1,axis=1) # Create shiftet data set for dummy variable\n",
    "dummy_school = shifted_edu -edu # Create dummy for attending school for an additional year.\n",
    "dummy_school = dummy_school.drop(['1990','1979'], axis=1) # Dropping year 1979 and 1990\n",
    "dummy_school.index.name = 'id' # Create id column\n",
    "panel_dummy_school = dummy_school.reset_index().melt(id_vars='id', var_name ='Year', value_name='Dummy_school') #Reformatting data\n",
    "\n",
    "edu_going_in = edu.shift(1, axis=1) # shift so that the value in 1980 is the value from 1979\n",
    "edu_going_in = edu.drop(['1990','1979'], axis=1) # Dropping year 1979 and 1990\n",
    "edu_going_in.index.name = 'id' # Creating id column\n",
    "panel_edu_going_in = edu_going_in.reset_index().melt(id_vars='id', var_name='Year', value_name='Education_going_in') # Reformatting data\n",
    "panel_edu = panel_edu.drop(columns='id') # Creating id column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum value of the DataFrame (excluding the identifier column): 6\n",
      "Maximum value of the DataFrame (excluding the identifier column): 20\n"
     ]
    }
   ],
   "source": [
    "# Find the minimum value of the DataFrame excluding the first column\n",
    "min_value = edu.iloc[:, 1:].values.min()\n",
    "\n",
    "# Find the maximum value of the DataFrame excluding the first column\n",
    "max_value = edu.iloc[:, 1:].values.max()\n",
    "\n",
    "print(\"Minimum value of the DataFrame (excluding the identifier column):\", min_value)\n",
    "print(\"Maximum value of the DataFrame (excluding the identifier column):\", max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the experience data set and setting it up\n",
    "\n",
    "exp = pd.read_csv('exp.data', delim_whitespace=True, header=None, index_col=0)\n",
    "exp.columns = new_column_names\n",
    "exp = exp.replace(-9999, np.nan)\n",
    "exp.index.name = 'id'\n",
    "panel_exp = exp.reset_index().melt(id_vars='id', var_name='Year', value_name='Experience') # Reformatting into classic panel data form\n",
    "\n",
    "diff_exp = exp.diff(axis=1) #Calculating difference in experience\n",
    "dummy_work = (diff_exp > 0).astype(int) #Creating dummy for working\n",
    "dummy_work = dummy_work.drop(['1979','1990'], axis=1) # Dropping year 1979 and 1990\n",
    "dummy_work.index.name = 'id' # Creating id column\n",
    "panel_dummy_work = dummy_work.reset_index().melt(id_vars='id', var_name ='Year', value_name='Dummy_work') #Reformatting \n",
    "\n",
    "exp_going_in = exp.shift(1, axis=1) # Shift axis in experience data set\n",
    "exp_going_in = exp_going_in.drop(['1990','1979'], axis=1) # Dropping year 1979 and 1990\n",
    "exp_going_in.index.name = 'id' # Creating id column\n",
    "panel_exp_going_in = exp_going_in.reset_index().melt(id_vars='id', var_name='Year', value_name='Experience_going_in') # Reformatting data set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating interruption dummy\n",
    "dummy_interrup = ((dummy_school == 0) & (dummy_work == 0)).astype(int)\n",
    "dummy_interrup.index.name = 'id' # Creating id column\n",
    "panel_dummy_interrup = dummy_interrup.reset_index().melt(id_vars='id', var_name ='Year', value_name='Dummy_interrup') # Reformatting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum value of the DataFrame (excluding NaN values and the identifier column): 0.0\n",
      "Maximum value of the DataFrame (excluding NaN values and the identifier column): 16.94\n"
     ]
    }
   ],
   "source": [
    "#Experience\n",
    "# Find the minimum value of the DataFrame excluding NaN values and the first column\n",
    "min_value = np.nanmin(exp.iloc[:, 1:].values)\n",
    "\n",
    "# Find the maximum value of the DataFrame excluding NaN values and the first column\n",
    "max_value = np.nanmax(exp.iloc[:, 1:].values)\n",
    "\n",
    "print(\"Minimum value of the DataFrame (excluding NaN values and the identifier column):\", min_value)\n",
    "print(\"Maximum value of the DataFrame (excluding NaN values and the identifier column):\", max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and setting up data for wage\n",
    "\n",
    "wage = pd.read_csv('wage.data', delim_whitespace=True, header=None, index_col=0) # Loading data\n",
    "wage.columns = new_column_names # Column names\n",
    "wage = wage.replace(-9999, np.nan) # Defining NaN values\n",
    "wage = wage.drop(['1979','1990'], axis=1) # Dropping year 1979 and 1990\n",
    "wage.index.name = 'id' # Creating id column\n",
    "panel_wage = wage.reset_index().melt(id_vars='id', var_name='Year', value_name='Wage') # Reformatting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum value of the DataFrame (excluding NaN values and the identifier column): 2.01\n",
      "Maximum value of the DataFrame (excluding NaN values and the identifier column): 36.82\n"
     ]
    }
   ],
   "source": [
    "# Find the minimum value of the DataFrame excluding NaN values and the first column\n",
    "min_value = np.nanmin(wage.iloc[:, 1:].values)\n",
    "\n",
    "# Find the maximum value of the DataFrame excluding NaN values and the first column\n",
    "max_value = np.nanmax(wage.iloc[:, 1:].values)\n",
    "\n",
    "print(\"Minimum value of the DataFrame (excluding NaN values and the identifier column):\", min_value)\n",
    "print(\"Maximum value of the DataFrame (excluding NaN values and the identifier column):\", max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging variables into one data set\n",
    "merged_df = pd.merge(panel_dummy_school, panel_edu_going_in, on = ['id','Year'])\n",
    "merged_df = pd.merge(merged_df, panel_dummy_interrup, on = ['id','Year'])\n",
    "merged_df = pd.merge(merged_df, panel_dummy_work, on = ['id','Year'])\n",
    "merged_df = pd.merge(merged_df, panel_exp_going_in, on = ['id','Year'])\n",
    "merged_df = pd.merge(merged_df, panel_wage, on = ['id','Year'])\n",
    "merged_df.to_csv('merged_data.data', sep='\\t', index=False) # Export DataFrame to a .data file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.15   0.2565 0.2279]\n",
      "[1.307  0.22   0.1948 0.0178]\n",
      "[ 2.116   0.2073  0.1776  0.0173 -0.1391]\n",
      "[ 2.10043  0.20726  0.1683   0.01545 -0.14545  0.43123 -0.04957 -0.34782]\n"
     ]
    }
   ],
   "source": [
    "# Laver OLS estimation\n",
    "dat = family.copy()\n",
    "dat['constant'] = np.ones(family.shape[0])\n",
    "dat['Family_income'] = dat['Family_income'] / 1000\n",
    "# Estimerer model (1)\n",
    "#For at få det rigtige intercept, trækker vi 6 fra y-værdien = highest grade completed, fordi stort set alle individer har gået 6 år i skole.\n",
    "y = edu[edu.columns[-1]].values-6\n",
    "X_m1 = dat[['constant','Dad_educ','Mom_educ']].values\n",
    "\n",
    "# Print model (1)\n",
    "betahat_m1 = np.linalg.inv(X_m1.T @ X_m1) @ X_m1.T @ y\n",
    "print(betahat_m1.round(4))\n",
    "\n",
    "#Print model (2)\n",
    "X_m2 = dat[['constant','Dad_educ','Mom_educ','Family_income']].values\n",
    "betahat_m2 = np.linalg.inv(X_m2.T @ X_m2) @ X_m2.T @ y\n",
    "print(betahat_m2.round(4))\n",
    "\n",
    "#Print model (3)\n",
    "X_m3 = dat[['constant','Dad_educ','Mom_educ','Family_income','Num_siblings']].values\n",
    "betahat_m3 = np.linalg.inv(X_m3.T @ X_m3) @ X_m3.T @ y\n",
    "print(betahat_m3.round(4))\n",
    "\n",
    "#Print model (4)\n",
    "X_m4 = dat[['constant','Dad_educ','Mom_educ','Family_income','Num_siblings','Nuclear','Urban','South']].values\n",
    "betahat_m4 = np.linalg.inv(X_m4.T @ X_m4) @ X_m4.T @ y\n",
    "print(betahat_m4.round(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8470.728866248894\n",
      "se_OLS_m1 =  [[0.26]\n",
      " [0.02]\n",
      " [0.03]]\n",
      "[0.26393335 0.01933999 0.02729107] [1.15002725 0.25646102 0.22794135]\n"
     ]
    }
   ],
   "source": [
    "# Calculate residuals\n",
    "res_OLS_m1 = y - X_m1@betahat_m1\n",
    "\n",
    "# Estimate variance\n",
    "K_m1 = X_m1.shape[1]\n",
    "N_m1 = X_m1.shape[0]\n",
    "SSR_m1 = res_OLS_m1.T@res_OLS_m1\n",
    "print(SSR_m1)\n",
    "sigma2_OLS_m1 = SSR_m1/(N_m1-K_m1)\n",
    "var_m1 = sigma2_OLS_m1*la.inv(X_m1.T@X_m1)\n",
    "\n",
    "# Calculate standard errors\n",
    "se_m1 = np.sqrt(np.diag(var_m1)).reshape(-1,1)\n",
    "\n",
    "# Display standard error\n",
    "print(\"se_OLS_m1 = \",se_m1.round(2))\n",
    "print(np.sqrt(var_m1.diagonal()), betahat_m1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08159917, 0.00043539, 0.00089316])"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ainv = la.inv(X_m1.T@X_m1)\n",
    "u2 = res_OLS_m1 ** 2\n",
    "xTu2 = X_m1.T * u2 \n",
    "cov = Ainv @ (xTu2 @ X_m1) @ Ainv\n",
    "se = np.sqrt(np.diag(cov))\n",
    "np.diag(cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "se_OLS_m2 =  [[0.2591]\n",
      " [0.0194]\n",
      " [0.027 ]\n",
      " [0.0021]]\n",
      "[0.0671 0.0004 0.0007 0.    ] [1.30695638 0.21995186 0.19476742 0.017803  ]\n"
     ]
    }
   ],
   "source": [
    "# Calculate residuals\n",
    "res_OLS_m2 = y - X_m2@betahat_m2\n",
    "\n",
    "# Estimate variance\n",
    "K_m2 = X_m2.shape[1]\n",
    "N_m2 = X_m2.shape[0]\n",
    "SSR_m2 = res_OLS_m2.T@res_OLS_m2\n",
    "sigma2_OLS_m2 = (np.array(SSR_m2/(N_m2-K_m2)))\n",
    "var_m2 = sigma2_OLS_m2*la.inv(X_m2.T@X_m2)\n",
    "\n",
    "# Calculate standard errors\n",
    "se_m2 = np.sqrt(var_m2.diagonal()).reshape(-1,1)\n",
    "\n",
    "# Display standard error\n",
    "print(\"se_OLS_m2 = \",se_m2.round(4))\n",
    "print(var_m2.diagonal().round(4), betahat_m2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\\begin{table}[H]\n",
      "    \\centering\n",
      "    \\begin{tabular}{lcccc}\n",
      "        \\hline\n",
      "        & Model 1 & Model 2 & Model 3 & Model 4 \\\\\n",
      "        \\hline\n",
      "        Constant & 1.15 & 1.307 & 2.116 & 2.1004 \\\\\n",
      "        Dad's Education & 0.2565 & 0.22 & 0.2073 & 0.2073 \\\\\n",
      "        Mom's Education & 0.2279 & 0.1948 & 0.1776 & 0.1683 \\\\\n",
      "        Family Income &  & 0.0178 & 0.0173 & 0.0155 \\\\\n",
      "        Number of Siblings &  &  & -0.1391 & -0.1454 \\\\\n",
      "        Nuclear Family &  &  &  & 0.4312 \\\\\n",
      "        Urban &  &  &  & -0.0496 \\\\\n",
      "        South &  &  &  & -0.3478 \\\\\n",
      "        \\hline\n",
      "    \\end{tabular}\n",
      "    \\caption{OLS Estimation Results}\n",
      "    \\label{tab:ols_results}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Collecting results\n",
    "results = {\n",
    "    'Model 1': betahat_m1.round(4),\n",
    "    'Model 2': betahat_m2.round(4),\n",
    "    'Model 3': betahat_m3.round(4),\n",
    "    'Model 4': betahat_m4.round(4)\n",
    "}\n",
    "\n",
    "# Create a list of coefficients names for the models\n",
    "coef_names = ['Constant', \"Dad's Education\", \"Mom's Education\", 'Family Income', 'Number of Siblings', 'Nuclear Family', 'Urban', 'South']\n",
    "\n",
    "# Constructing the LaTeX table\n",
    "latex_table = \"\"\"\n",
    "\\\\begin{table}[H]\n",
    "    \\\\centering\n",
    "    \\\\begin{tabular}{lcccc}\n",
    "        \\\\hline\n",
    "        & Model 1 & Model 2 & Model 3 & Model 4 \\\\\\\\\n",
    "        \\\\hline\n",
    "\"\"\"\n",
    "for i, coef in enumerate(coef_names):\n",
    "    latex_table += \"        {} & {} & {} & {} & {} \\\\\\\\\\n\".format(\n",
    "        coef,\n",
    "        results['Model 1'][i] if i < len(results['Model 1']) else '',\n",
    "        results['Model 2'][i] if i < len(results['Model 2']) else '',\n",
    "        results['Model 3'][i] if i < len(results['Model 3']) else '',\n",
    "        results['Model 4'][i] if i < len(results['Model 4']) else ''\n",
    "    )\n",
    "latex_table += \"\"\"        \\\\hline\n",
    "    \\\\end{tabular}\n",
    "    \\\\caption{OLS Estimation Results}\n",
    "    \\\\label{tab:ols_results}\n",
    "\\\\end{table}\n",
    "\"\"\"\n",
    "\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
